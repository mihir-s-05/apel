# NOTE: 1B-scale scaffold. Intended for multi-GPU `torchrun` on A100/H100-class hardware.
# For true parameter sharding at this scale, consider adding FSDP in addition to DDP+ZeRO(optimizer-state).

seed: 42
device: cuda

data:
  source: fineweb_edu
  train_split: train
  val_split: train
  streaming: true
  min_chars: 64
  token_cache: true
  token_cache_dir: runs/fineweb_edu_scale_1b/token_cache
  reuse_token_cache: true
  max_train_examples: 2000000
  max_val_examples: 50000
  max_train_tokens: 2000000000
  max_val_tokens: 20000000
  tokenizer_fit_max_examples: 200000
  tokenizer_fit_max_chars: 40000000

tokenizer:
  type: bpe
  vocab_size: 32768
  min_frequency: 2
  byte_level: true
  lowercase: false
  special_tokens:
    - "<pad>"
    - "<bos>"
    - "<eos>"
    - "<unk>"

model:
  version: v2_planner_required
  num_plan_states: 4
  num_experts: 4
  chunk_size: 16
  token_dim: 1024
  hidden_dim: 4096
  num_layers: 5
  dropout: 0.1
  planner_self_bias: 2.0
  planner_context_scale: 1.0
  future_horizon_chunks: 2
  plan_commitment: gumbel_st
  commitment_warmup_steps: 2000
  commitment_ramp_steps: 2000
  plan_temperature_start: 1.10
  plan_temperature_end: 0.70
  token_filtering: true
  lookahead_horizon: 2
  lookahead_feedback_scale: 0.25
  async_planner: true

train:
  out_dir: runs/fineweb_edu_scale_1b
  seq_len: 1024
  stride: 1024
  batch_size: auto
  adaptive_batch:
    enabled: true
    probe_batch_size: 1
    min_batch_size: 1
    max_batch_size: 8
    safety_factor: 0.9
    reprobe_interval_steps: 0
  grad_accum_steps: 1
  precision: bf16
  lr: 0.0001
  lr_schedule: cosine
  warmup_steps: 2000
  min_lr_ratio: 0.1
  weight_decay: 0.01
  grad_clip: 1.0
  max_steps: 200000
  log_interval: 50
  eval_interval: 2000
  val_batches: 8
  eval_planner_diagnostics: false
  final_eval_planner_diagnostics: true
  preview_interval: 2000
  preview_prompt: "In a surprising turn,"
  preview_tokens: 160
  loss_weights:
    usage_balance: 0.05
    boundary_entropy: 0.02
    future_contrastive: 0.08
    plan_js_div: 0.10
    rep_unlikelihood: 0.0
    rep_window: 64
  save_interval: 5000
  save_optimizer_state: false
  fused_adamw: true
  allow_tf32: true
  matmul_precision: high
  compile:
    enabled: true
    mode: reduce-overhead
    fullgraph: false
    dynamic: false
  distributed:
    backend: nccl
    zero_optimizer: true
  num_workers: 8
  prefetch_factor: 4
  persistent_workers: true
  pin_memory: true
